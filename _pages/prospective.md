---
layout: page
permalink: /prospective/
title: prospective students
description:
nav: false
---

&nbsp;
&nbsp;

### Am I recruiting?
Yes, I am actively recruiting PhD students to USC in 🍁 Fall 2022! Thanks for your interest ☀️ in my research!
[Applications](https://www.cs.usc.edu/ph-d-application-information/) are open, and the deadline to submit your application is [Dec 15th, 2021](https://days.to/until/15-december).
USC waived GRE scores ⚡ for graduate admissions in Fall 2022 and offers [fee waivers](https://gradadm.usc.edu/lightboxes/us-students-fee-waivers/) to select applicants.


Please consider <u>selecting</u> [my name](https://www.cs.usc.edu/directory/faculty/profile/?lname=Swayamdipta&fname=Swabha) <u>as a potential advisor</u>, especially if your research interests match [mine](/publications/), even though your research background might be different.
I'm broadly interested in

<hr>

##### 📚 Estimation of Dataset Quality:
What makes a dataset valuable for training high-capacity models, pretrained on large amounts of unlabeled data? Our [Dataset Cartography](https://arxiv.org/abs/2009.10795) offers point estimates, and [V-Information](https://arxiv.org/abs/2110.08420) offers aggregate estimates of dataset quality. Can these estimates be computed without taking into account specific model families?

###### 🎨 Creative Data Curation:
Can we use the lessons above to create high quality datasets, more suitable for modern NLP models? Our work on [Generative Data Augmentation](https://arxiv.org/abs/2004.11546) showed that this is possible to automate to some extent, either via [controlled generation](https://arxiv.org/abs/2105.03023) or [selection](https://arxiv.org/abs/2004.10964). Is it possible to create collaborative setups between humans and generative models to this end?

##### 🤖 Robustness to Model Biases:
<!-- Given that one of the loftiest goals in machine learning is generalization, we need to ensure that -->
Current large scale models tend to [rely on spurious biases to make the correct predictions](https://arxiv.org/abs/1803.02324). The reduction of undesirable biases could be done via data selection, as in [AFLite](https://arxiv.org/abs/2002.04108) or by altering [learning objectives](https://arxiv.org/abs/1909.03683). However, the discovery of such biases is much trickier and task-dependent.
Going beyond solutions presented in [AFLite](https://arxiv.org/abs/2002.04108), how can we find spurious correlations automatically?

Particularly harmful are social biases in models, such as those which correlate surface markers of certain dialects with subjective attributes such as toxicity. [Social biases cannot be mitigated easily](https://arxiv.org/abs/2102.00086) and require rethinking data collection and task design, as we show in our [latest paper](https://arxiv.org/abs/2111.07997).

##### 🕵🏼‍♀️ Model Interpretability and 👩🏼‍🔬 Meticulous Evaluation:
What cannot be measured, cannot be improved. How can we make our [models explain their decisions to human users](https://arxiv.org/abs/2103.01378)? Moreover, as tasks previously considered extremely difficult are getting easier, how do we best [adapt our evaluation methods](https://arxiv.org/abs/2102.01454) to ensure fair evaluation?

<hr>


### Should you send me an email?

###### If you're NOT at USC:
You do <em>not</em> have to email me, especially since I haven't officially started at USC and do not have any control over the admissions process. My recommendation to you is to apply through the regular PhD program [admissions](https://www.cs.usc.edu/ph-d-application-information/) by December 15th and USC will be in touch with you regarding the next steps. I will go over every single application that lists me as a potential advisor. 🤞

###### If you're' already at USC:

Please feel free to email me if you are looking for advising or TAing. However, you should know that there is not much I can officially do, just yet. It would be great to be introduced and learn about your interests, though! 👋
