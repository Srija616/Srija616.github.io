---
layout: post
permalink: /bio/
title: bio
description:
nav: false
---

Swabha Swayamdipta is a postdoctoral researcher at the Allen Institute for AI and soon-to-be the Gabilan Assistant Professor and an Assistant Professor of Computer Science at the University of Southern California (starting Fall 2022). Her research interests are in natural language processing, with a focus on studying data distributions to automatically uncover redundancies, annotation and collection artifacts in data, which result in undesirable model biases. Swabha received her PhD from Carnegie Mellon University, and holds a Masters degree from Columbia University. Her work has received an outstanding paper award at NeurIPS 2021 and an honorable mention award for the best paper at ACL 2020.

<!-- *Good biases*, such as [structural inductive biases](https://www.aclweb.org/anthology/D18-1412) help language understanding - check out my [PhD thesis](/assets/pdf/swabha_thesis.pdf) on these. -->
<!-- But biases can be *undesirable*, e.g. [spurious correlations](https://arxiv.org/abs/2002.04108) commonly found in crowd-sourced, large-scale datasets due to [annotation artifacts](https://arxiv.org/abs/1803.02324), or social prejudices of human annotators and task designers, which are [difficult to rid](https://arxiv.org/abs/2102.00086)! -->
